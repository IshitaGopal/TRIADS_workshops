import requests as req
import time
import pandas as pd



#https://medium.com/codex/web-scraping-the-new-york-times-articles-with-python-part-i-e2d6fc02d4e0
API_KEY = "5cbst07gUvIjdFwF1A61wh18GnYX5GSA"
TOPIC='Climate Change' # keyword
2024
url=f"https://api.nytimes.com/svc/search/v2/articlesearch.json?q={TOPIC}&api-key={API_KEY}"
"https://api.nytimes.com/svc/archive/v1/%7Byear%7D/%7Bmonth%7D.json?"
response = req.get(url).json()


response.keys()


data = pd.DataFrame(response['response']["docs"])


data.web_url[1]



data["multimedia"][1][1]



# https://github.com/nytimes/public_api_specs/issues/52
import urllib.request 
from PIL import Image 
  
# Retrieving the resource located at the URL 
# and storing it in the file name a.png 
url = "https://www.nytimes.com/images/2024/04/09/books/review/09Aldern/09Aldern-articleLarge.jpg" 
urllib.request.urlretrieve(url, "images/img1.png") 
#requests.get(url, stream = True)




# Opening the image and displaying it (to confirm its presence) 
img = Image.open(r"img.png") 
img.show()



#https://github.com/ovh/ai-training-examples/blob/main/notebooks/computer-vision/image-classification/tensorflow/resnet50/notebook-resnet-transfer-learning-image-classification.ipynb


#https://martinheinz.dev/blog/31


year = 2024
month = 2
url = f"https://api.nytimes.com/svc/archive/v1/{year}/{month}.json"


 # Parameters (if any)
params = {'api-key': API_KEY}

# Make the GET request
response = req.get(url, params=params)



#response.json()


apikey = "5cbst07gUvIjdFwF1A61wh18GnYX5GSA"
query = "climate change"
begin_date = "20240101"  # YYYYMMDD
#filter_query = "\"body:(\"Trump\") AND glocations:(\"WASHINGTON\")\""  # http://www.lucenetutorial.com/lucene-query-syntax.html
page = "0"  # <0-100>
sort = "relevance"  # newest, oldest

query_url = f"https://api.nytimes.com/svc/search/v2/articlesearch.json?" \
            f"q={query}" \
            f"&api-key={apikey}" \
            f"&begin_date={begin_date}" \
            #f"&fq={filter_query}" \
            f"&page={page}" \
            f"&sort={sort}"

r = requests.get(query_url)
pprint(r.json())


import requests
from pprint import pprint

apikey = "5cbst07gUvIjdFwF1A61wh18GnYX5GSA"

query = "climate&change"
begin_date = "20240101"  # YYYYMMDD
filter_query = "\"body:(\"Trump\") AND glocations:(\"WASHINGTON\")\""  # http://www.lucenetutorial.com/lucene-query-syntax.html
page = "0"  # <0-100>
sort = "relevance"  # newest, oldest
query_url = f"https://api.nytimes.com/svc/search/v2/articlesearch.json?" \
            f"q={query}" \
            f"&api-key={apikey}" \
            f"&begin_date={begin_date}" \
            f"&fq={filter_query}" \
            f"&page={page}" \
            f"&sort={sort}"

r = requests.get(query_url).json()
#pprint(r)





data = pd.DataFrame(r["response"]["docs"])


data.head()


data.columns


data.shape


data.headline[1]


data.snippet[1]


data.section_name.value_counts()


data.news_desk



